<!doctype html><html lang=en dir=" auto">
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta charset=utf-8>
<meta name=Share-Source-Verification content="https://blog.zhangyingwei.com/">
<meta http-equiv=cache-control content="no-transform">
<meta http-equiv=cache-control content="no-siteapp">
<meta name=renderer content="webkit">
<meta name=apple-mobile-web-app-capable content="yes">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta property="og:title" content="探索 Kafka 消息丢失的问题和解决方案">
<meta property="og:image" content="/images/favicon64.ico">
<meta name=msvalidate.01 content="1B50C3A24BF817BB86D82C8429075AE4">
<meta name=bytedance-verification-code content="rjX6knbDoNxpR4Asxe2M">
<meta name=robots content="index, follow">
<title>探索 Kafka 消息丢失的问题和解决方案 | 胡说</title>
<meta name=keywords content="胡说,静态博客,张英伟,张英伟的个人博客,SpringBoot,Java,Kafka">
<meta name=description content="在构建基于 Kafka 的消息处理系统中，消息丢失是一个需要深入研究的重要问题。强大的系统不仅依赖于其功能，而且依赖于其可靠性。因此，理解消息丢失的原因，并采取必要的措施确保消息的一致性和完整性，是构建高效可靠消息系统的重要组成部分。本文将详细分析 Kafka 消息丢失的主要原因，并提供一系列策略来解决这个问题。
消息丢失的原因  生产者端问题： 在 Kafka 系统中，生产者负责发送消息。然而，由于网络故障或其他未知问题，生产者可能无法成功发送消息到 Kafka 服务器。 Kafka 服务端问题： Kafka 服务器可能会因为硬件故障、磁盘满或其他异常情况导致消息丢失。 消费者端问题： 消费者负责处理接收到的消息。但是，消费者在处理消息时可能会出现错误或崩溃，导致消息未被正确处理。  解决方案与措施 生产者端相关方案与措施  发送消息处理回调方法  由于消息的常规发送采用的异步方式，所以通常会忽略掉回调处理，为了保证消息的发送质量，一定需要对回调信息进行处理或者改为同步发送。
producer.send(new ProducerRecord<>(topic, messageKey, messageStr), new CallBack({...}); 设置有效的重试策略以及 acks 配置  我们可以在生产者端设置一个有效的重试策略，保证消息成功发送。例如，我们可以使用指数退避算法进行重试。这种算法会在每次重试失败后等待更长的时间，从而减轻服务器的压力，并增加消息成功发送的概率。
通过设置 Producer acks 机制，我们可以确保生产者收到 Kafka 服务器的确认，知晓消息是否被成功提交。
 acks=0： 生产者在发送消息后不会等待任何确认，直接将消息视为发送成功。这种设置下，可能会出现消息丢失的情况，因为生产者不会等待服务器的任何确认即认为消息发送成功。 acks=1： 生产者在发送消息后会等待 Leader Broker 的确认，确认后即视为消息发送成功。这种设置下，消息的可靠性得到一定程度的保证，但仍有可能发生 Leader Broker 宕机导致消息丢失的情况。 acks=all： 生产者在发送消息后会等待 Leader Broker 和所有副本的确认，确认后才视为消息发送成功。这种设置下，消息的可靠性和一致性得到最高级别的保证，但同时也会增加网络延迟和资源消耗。  import org.apache.kafka.clients.producer.*; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; public class KafkaProducerExample { private static final String TOPIC_NAME = &#34;my-topic&#34;; private static final String BOOTSTRAP_SERVERS = &#34;localhost:9092&#34;; public static void main(String[] args) { Properties props = new Properties(); props.">
<meta name=author content="zhangyw">
<link rel=canonical href=https://blog.zhangyingwei.com/posts/2024m4d2h10m23s15/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.64f3692c16cf6e6d25580c5ffff1fefc9804abc450b958d1b31de5d6a14c5b8e.css integrity="sha256-ZPNpLBbPbm0lWAxf//H+/JgEq8RQuVjRsx3l1qFMW44=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://blog.zhangyingwei.com/images/favicon64.ico>
<link rel=icon type=image/png sizes=16x16 href=https://blog.zhangyingwei.com/images/favicon16.ico>
<link rel=icon type=image/png sizes=32x32 href=https://blog.zhangyingwei.com/images/favicon32.ico>
<link rel=apple-touch-icon href=https://blog.zhangyingwei.com/apple-touch-icon.png>
<link rel=mask-icon href=https://blog.zhangyingwei.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><link href=https://hushuo.zhangyingwei.com/NotoSerifSC.css rel=stylesheet>
<link href=https://hushuo.zhangyingwei.com/JetBrainsMono.css rel=stylesheet>
<script>var _hmt=_hmt||[];(function(){var a=document.createElement("script"),b;a.src="https://hm.baidu.com/hm.js?ba380df4e327c711daf3b841b4089ce4",b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script>
<script async src=https://umami.zhangyingwei.com/script.js data-website-id=cb41ccbd-6ee9-4587-9c03-d872f2d10472></script><meta property="og:title" content="探索 Kafka 消息丢失的问题和解决方案">
<meta property="og:description" content="在构建基于 Kafka 的消息处理系统中，消息丢失是一个需要深入研究的重要问题。强大的系统不仅依赖于其功能，而且依赖于其可靠性。因此，理解消息丢失的原因，并采取必要的措施确保消息的一致性和完整性，是构建高效可靠消息系统的重要组成部分。本文将详细分析 Kafka 消息丢失的主要原因，并提供一系列策略来解决这个问题。
消息丢失的原因  生产者端问题： 在 Kafka 系统中，生产者负责发送消息。然而，由于网络故障或其他未知问题，生产者可能无法成功发送消息到 Kafka 服务器。 Kafka 服务端问题： Kafka 服务器可能会因为硬件故障、磁盘满或其他异常情况导致消息丢失。 消费者端问题： 消费者负责处理接收到的消息。但是，消费者在处理消息时可能会出现错误或崩溃，导致消息未被正确处理。  解决方案与措施 生产者端相关方案与措施  发送消息处理回调方法  由于消息的常规发送采用的异步方式，所以通常会忽略掉回调处理，为了保证消息的发送质量，一定需要对回调信息进行处理或者改为同步发送。
producer.send(new ProducerRecord<>(topic, messageKey, messageStr), new CallBack({...}); 设置有效的重试策略以及 acks 配置  我们可以在生产者端设置一个有效的重试策略，保证消息成功发送。例如，我们可以使用指数退避算法进行重试。这种算法会在每次重试失败后等待更长的时间，从而减轻服务器的压力，并增加消息成功发送的概率。
通过设置 Producer acks 机制，我们可以确保生产者收到 Kafka 服务器的确认，知晓消息是否被成功提交。
 acks=0： 生产者在发送消息后不会等待任何确认，直接将消息视为发送成功。这种设置下，可能会出现消息丢失的情况，因为生产者不会等待服务器的任何确认即认为消息发送成功。 acks=1： 生产者在发送消息后会等待 Leader Broker 的确认，确认后即视为消息发送成功。这种设置下，消息的可靠性得到一定程度的保证，但仍有可能发生 Leader Broker 宕机导致消息丢失的情况。 acks=all： 生产者在发送消息后会等待 Leader Broker 和所有副本的确认，确认后才视为消息发送成功。这种设置下，消息的可靠性和一致性得到最高级别的保证，但同时也会增加网络延迟和资源消耗。  import org.apache.kafka.clients.producer.*; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; public class KafkaProducerExample { private static final String TOPIC_NAME = &#34;my-topic&#34;; private static final String BOOTSTRAP_SERVERS = &#34;localhost:9092&#34;; public static void main(String[] args) { Properties props = new Properties(); props.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://blog.zhangyingwei.com/posts/2024m4d2h10m23s15/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2024-01-02T10:23:15+08:00">
<meta property="article:modified_time" content="2024-01-02T10:23:15+08:00"><meta property="og:site_name" content="胡说">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.zhangyingwei.com/posts/"},{"@type":"ListItem","position":2,"name":"探索 Kafka 消息丢失的问题和解决方案","item":"https://blog.zhangyingwei.com/posts/2024m4d2h10m23s15/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"探索 Kafka 消息丢失的问题和解决方案","name":"探索 Kafka 消息丢失的问题和解决方案","description":"在构建基于 Kafka 的消息处理系统中，消息丢失是一个需要深入研究的重要问题。强大的系统不仅依赖于其功能，而且依赖于其可靠性。因此，理解消息丢失的原因，并采取必要的措施确保消息的一致性和完整性，是构建高效可靠消息系统的重要组成部分。本文将详细分析 Kafka 消息丢失的主要原因，并提供一系列策略来解决这个问题。\n消息丢失的原因  生产者端问题： 在 Kafka 系统中，生产者负责发送消息。然而，由于网络故障或其他未知问题，生产者可能无法成功发送消息到 Kafka 服务器。 Kafka 服务端问题： Kafka 服务器可能会因为硬件故障、磁盘满或其他异常情况导致消息丢失。 消费者端问题： 消费者负责处理接收到的消息。但是，消费者在处理消息时可能会出现错误或崩溃，导致消息未被正确处理。  解决方案与措施 生产者端相关方案与措施  发送消息处理回调方法  由于消息的常规发送采用的异步方式，所以通常会忽略掉回调处理，为了保证消息的发送质量，一定需要对回调信息进行处理或者改为同步发送。\nproducer.send(new ProducerRecord\u0026lt;\u0026gt;(topic, messageKey, messageStr), new CallBack({...}); 设置有效的重试策略以及 acks 配置  我们可以在生产者端设置一个有效的重试策略，保证消息成功发送。例如，我们可以使用指数退避算法进行重试。这种算法会在每次重试失败后等待更长的时间，从而减轻服务器的压力，并增加消息成功发送的概率。\n通过设置 Producer acks 机制，我们可以确保生产者收到 Kafka 服务器的确认，知晓消息是否被成功提交。\n acks=0： 生产者在发送消息后不会等待任何确认，直接将消息视为发送成功。这种设置下，可能会出现消息丢失的情况，因为生产者不会等待服务器的任何确认即认为消息发送成功。 acks=1： 生产者在发送消息后会等待 Leader Broker 的确认，确认后即视为消息发送成功。这种设置下，消息的可靠性得到一定程度的保证，但仍有可能发生 Leader Broker 宕机导致消息丢失的情况。 acks=all： 生产者在发送消息后会等待 Leader Broker 和所有副本的确认，确认后才视为消息发送成功。这种设置下，消息的可靠性和一致性得到最高级别的保证，但同时也会增加网络延迟和资源消耗。  import org.apache.kafka.clients.producer.*; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; public class KafkaProducerExample { private static final String TOPIC_NAME = \u0026#34;my-topic\u0026#34;; private static final String BOOTSTRAP_SERVERS = \u0026#34;localhost:9092\u0026#34;; public static void main(String[] args) { Properties props = new Properties(); props.","keywords":["胡说","静态博客","张英伟","张英伟的个人博客","SpringBoot","Java","Kafka"],"articleBody":"在构建基于 Kafka 的消息处理系统中，消息丢失是一个需要深入研究的重要问题。强大的系统不仅依赖于其功能，而且依赖于其可靠性。因此，理解消息丢失的原因，并采取必要的措施确保消息的一致性和完整性，是构建高效可靠消息系统的重要组成部分。本文将详细分析 Kafka 消息丢失的主要原因，并提供一系列策略来解决这个问题。\n消息丢失的原因  生产者端问题： 在 Kafka 系统中，生产者负责发送消息。然而，由于网络故障或其他未知问题，生产者可能无法成功发送消息到 Kafka 服务器。 Kafka 服务端问题： Kafka 服务器可能会因为硬件故障、磁盘满或其他异常情况导致消息丢失。 消费者端问题： 消费者负责处理接收到的消息。但是，消费者在处理消息时可能会出现错误或崩溃，导致消息未被正确处理。  解决方案与措施 生产者端相关方案与措施  发送消息处理回调方法  由于消息的常规发送采用的异步方式，所以通常会忽略掉回调处理，为了保证消息的发送质量，一定需要对回调信息进行处理或者改为同步发送。\nproducer.send(new ProducerRecord(topic, messageKey, messageStr), new CallBack({...}); 设置有效的重试策略以及 acks 配置  我们可以在生产者端设置一个有效的重试策略，保证消息成功发送。例如，我们可以使用指数退避算法进行重试。这种算法会在每次重试失败后等待更长的时间，从而减轻服务器的压力，并增加消息成功发送的概率。\n通过设置 Producer acks 机制，我们可以确保生产者收到 Kafka 服务器的确认，知晓消息是否被成功提交。\n acks=0： 生产者在发送消息后不会等待任何确认，直接将消息视为发送成功。这种设置下，可能会出现消息丢失的情况，因为生产者不会等待服务器的任何确认即认为消息发送成功。 acks=1： 生产者在发送消息后会等待 Leader Broker 的确认，确认后即视为消息发送成功。这种设置下，消息的可靠性得到一定程度的保证，但仍有可能发生 Leader Broker 宕机导致消息丢失的情况。 acks=all： 生产者在发送消息后会等待 Leader Broker 和所有副本的确认，确认后才视为消息发送成功。这种设置下，消息的可靠性和一致性得到最高级别的保证，但同时也会增加网络延迟和资源消耗。  import org.apache.kafka.clients.producer.*; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; public class KafkaProducerExample { private static final String TOPIC_NAME = \"my-topic\"; private static final String BOOTSTRAP_SERVERS = \"localhost:9092\"; public static void main(String[] args) { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 设置重试次数为3次  props.put(ProducerConfig.RETRIES_CONFIG, 3); // 指数退避算法参数 \t// 初始重试间隔为1秒 \tprops.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 1000); // 最大重试间隔为30秒 \tprops.put(ProducerConfig.RETRY_BACKOFF_MAX_MS_CONFIG, 30000); // 设置 acks 配置为 all \tproperties.setProperty(ProducerConfig.ACKS_CONFIG, \"all\"); KafkaProducerString, String producer = new KafkaProducer(props); // ... 其他业务逻辑  } } 启用 Kafka 日志压缩  Kafka 提供了日志压缩功能，这可以减少磁盘空间的使用，并提高消息存储的可靠性。通过这种方式，我们可以减少因磁盘满导致的消息丢失风险。\nimport org.apache.kafka.clients.producer.*; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; public class KafkaProducerExample { private static final String TOPIC_NAME = \"my-topic\"; private static final String BOOTSTRAP_SERVERS = \"localhost:9092\"; public static void main(String[] args) { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 其他设置...  // 启用日志压缩，使用gzip压缩算法  props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, \"gzip\"); KafkaProducerString, String producer = new KafkaProducer(props); // ... 其他业务逻辑  } } Kafka 服务端相关方案与措施 在 Kafka 服务端，要保证消息的可靠性，需要从几方面考虑\n合理的配置\n 根据数据量级，配置合理的 partition 数量，提高吞吐量，避免性能瓶颈导致消息丢失  高可用：\n 多副本配置： 在 Kafka 集群中设置多个副本，以确保即使某些 Broker 发生故障，仍然能够保证消息的可用性和一致性 ISR（In-Sync Replicas）机制： 使用 ISR 机制来确保所有副本之间的同步性，只有在所有 ISR 中的副本都同步成功后才认为消息发送成功 Controller 选举： 配置 Controller 选举机制，确保 Kafka 集群中的 Controller 能够及时处理 Broker 的故障和切换  数据持久化和日志管理：\n 数据持久化策略： 配置合适的数据持久化策略，例如使用持久化日志来存储消息，保证消息不会因为服务重启或异常导致丢失。 日志管理和清理： 定期清理过期的日志段（log segment），避免日志文件过大导致磁盘空间不足，同时确保消息的及时清理和归档。  监控和故障恢复：\n 监控和报警： 配置监控系统，实时监测 Kafka 集群的运行状态和性能指标，并设置报警机制，在出现异常或性能下降时及时发现并处理。 故障自愈： 配置自动故障恢复机制，例如使用 Kafka 的 Controller 自动进行 Broker 的故障检测和切换，确保集群在发生故障时能够快速恢复。  消费者端解决方案与措施 手动维护 offset\n 将 enable.auto.commit 设置为 false，并且在消费者端手动提交偏移量。 使用较小的 auto.commit.interval.ms 值，以减少自动提交偏移量的时间间隔，提高偏移量的提交频率。  import org.apache.kafka.clients.consumer.*; import org.apache.kafka.common.TopicPartition; import redis.clients.jedis.Jedis; import java.time.Duration; import java.util.Collections; import java.util.Properties; public class KafkaConsumerWithRedisOffsetOnStartup { public static void main(String[] args) { String kafkaBootstrapServers = \"kafka-broker1:9092,kafka-broker2:9092\"; String kafkaTopic = \"test-topic\"; String groupId = \"test-consumer-group\"; String redisHost = \"localhost\"; int redisPort = 6379; // Kafka Consumer 配置  Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\"); // 关闭自动提交偏移量  props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"100\"); // 设置自动提交偏移量的时间间隔为 100 毫秒  KafkaConsumerString, String consumer = new KafkaConsumer(props); // Redis 连接  Jedis jedis = new Jedis(redisHost, redisPort); try { // 从 Redis 中获取偏移量  MapTopicPartition, Long offsets = getOffsetsFromRedis(jedis, kafkaTopic, groupId); // 订阅主题并设置偏移量  consumer.subscribe(Collections.singleton(kafkaTopic), new ConsumerRebalanceListener() { @Override public void onPartitionsRevoked(CollectionTopicPartition partitions) {} @Override public void onPartitionsAssigned(CollectionTopicPartition partitions) { for (TopicPartition partition : partitions) { consumer.seek(partition, offsets.getOrDefault(partition, 0L)); } } }); while (true) { ConsumerRecordsString, String records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecordString, String record : records) { System.out.println(\"Received message: \" + record.value()); // 处理消息...  // 手动提交偏移量到 Redis  saveOffsetInRedis(jedis, record.topic(), record.partition(), record.offset()); // 手动提交偏移量到 Kafka  consumer.commitSync(Collections.singletonMap(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1))); } } } finally { consumer.close(); jedis.close(); } } private static MapTopicPartition, Long getOffsetsFromRedis(Jedis jedis, String topic, String groupId) { MapTopicPartition, Long offsets = new HashMap(); for (String key : jedis.keys(\"offset-\" + topic + \"-*\")) { String[] parts = key.split(\"-\"); int partition = Integer.parseInt(parts[parts.length - 1]); long offset = Long.parseLong(jedis.get(key)); offsets.put(new TopicPartition(topic, partition), offset); } return offsets; } private static void saveOffsetInRedis(Jedis jedis, String topic, int partition, long offset) { String key = \"offset-\" + topic + \"-\" + partition; jedis.set(key, String.valueOf(offset)); } } 总结 总得来说，关于消息可靠性的保证，需要从生产端、服务端、消费端三个方面综合考虑，不是仅仅一个方面的问题。\n拓展 Kafka 官方常用工具\n# 查看某个topic的message数量 $ ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test_topic # 查看consumer Group列表 $ ./kafka-consumer-groups.sh --list --bootstrap-server 192.168.88.108:9092 # 查看 offset 消费情况 $ ./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group console-consumer-1152 --describe GROUP TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-ID console-consumer-1152 test_topic 0 - 4 - consumer-console-consumer-1152-1-2703ea2b-b62d-4cfd-8950-34e8c321b942 /127.0.0.1 consumer-console-consumer-1152-1 Kafka 日志刷盘机制\n# 推荐采用默认值，即不配置该配置，交由操作系统自行决定何时落盘，以提升性能。 # 针对 broker 配置： log.flush.interval.messages=10000 # 日志落盘消息条数间隔，即每接收到一定条数消息，即进行log落盘。 log.flush.interval.ms=1000 # 日志落盘时间间隔，单位ms，即每隔一定时间，即进行log落盘。 # 针对 topic 配置： flush.messages.flush.ms=1000 # topic下每1s刷盘 flush.messages=1 # topic下每个消息都落盘 # 查看 Linux 后台线程执行配置 $ sysctl -a | grep dirty vm.dirty_background_bytes = 0 vm.dirty_background_ratio = 10 # 表示当脏页占总内存的的百分比超过这个值时，后台线程开始刷新脏页。 vm.dirty_bytes = 0 vm.dirty_expire_centisecs = 3000 # 表示脏数据多久会被刷新到磁盘上（30秒）。 vm.dirty_ratio = 20 vm.dirty_writeback_centisecs = 500 # 表示多久唤醒一次刷新脏页的后台线程（５秒）。 vm.dirtytime_expire_seconds = 43200 ","wordCount":"614","inLanguage":"en","datePublished":"2024-01-02T10:23:15+08:00","dateModified":"2024-01-02T10:23:15+08:00","author":{"@type":"Person","name":"zhangyw"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.zhangyingwei.com/posts/2024m4d2h10m23s15/"},"publisher":{"@type":"Organization","name":"胡说","logo":{"@type":"ImageObject","url":"https://blog.zhangyingwei.com/images/favicon64.ico"}}}</script>
</head>
<body class="font-activate bg-color mt-20" id="
    top">
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class="header font-activate sticky-element shadow-b">
<nav class=nav>
<div class=logo>
<a href=https://blog.zhangyingwei.com/ accesskey=h title="胡说 (Alt + H)">胡说</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://blog.zhangyingwei.com/series/ title=系列文章>
<span>系列文章</span>
</a>
</li>
<li>
<a href=https://blog.zhangyingwei.com/archives/ title=归档>
<span>归档</span>
</a>
</li>
<li>
<a href=https://blog.zhangyingwei.com/tags/ title=标签>
<span>标签</span>
</a>
</li>
</ul>
</nav>
</header><div style=height:20px></div>
<main class="main font-activate bg-color">
<article class="post-single item-padding">
<header class=post-header>
<h1 class=post-title>
探索 Kafka 消息丢失的问题和解决方案
</h1>
<div class=post-info>2024/01/02
<ul id=series>
🅰️
<li> <a href=https://blog.zhangyingwei.com/%20topics/java-%E7%B3%BB%E5%88%97>Java 系列</a> </li>
</ul>
<ul id=categories>
✨
<li><a href=https://blog.zhangyingwei.com/%20categories/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB>经验分享</a> </li>
</ul>
</div>
</header>
<div class=post-content><p>在构建基于 Kafka 的消息处理系统中，消息丢失是一个需要深入研究的重要问题。强大的系统不仅依赖于其功能，而且依赖于其可靠性。因此，理解消息丢失的原因，并采取必要的措施确保消息的一致性和完整性，是构建高效可靠消息系统的重要组成部分。本文将详细分析 Kafka 消息丢失的主要原因，并提供一系列策略来解决这个问题。</p>
<h2 id=消息丢失的原因>消息丢失的原因<a hidden class=anchor aria-hidden=true href=#消息丢失的原因>#</a></h2>
<ol>
<li><strong>生产者端问题：</strong> 在 Kafka 系统中，生产者负责发送消息。然而，由于网络故障或其他未知问题，生产者可能无法成功发送消息到 Kafka 服务器。</li>
<li><strong>Kafka 服务端问题：</strong> Kafka 服务器可能会因为硬件故障、磁盘满或其他异常情况导致消息丢失。</li>
<li><strong>消费者端问题：</strong> 消费者负责处理接收到的消息。但是，消费者在处理消息时可能会出现错误或崩溃，导致消息未被正确处理。</li>
</ol>
<h2 id=解决方案与措施>解决方案与措施<a hidden class=anchor aria-hidden=true href=#解决方案与措施>#</a></h2>
<h3 id=生产者端相关方案与措施>生产者端相关方案与措施<a hidden class=anchor aria-hidden=true href=#生产者端相关方案与措施>#</a></h3>
<ol>
<li>发送消息处理回调方法</li>
</ol>
<p>由于消息的常规发送采用的异步方式，所以通常会忽略掉回调处理，为了保证消息的发送质量，一定需要对回调信息进行处理或者改为同步发送。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java>producer<span style=color:#f92672>.</span><span style=color:#a6e22e>send</span><span style=color:#f92672>(</span><span style=color:#66d9ef>new</span> ProducerRecord<span style=color:#f92672>&lt;&gt;(</span>topic<span style=color:#f92672>,</span> messageKey<span style=color:#f92672>,</span> messageStr<span style=color:#f92672>),</span>  <span style=color:#66d9ef>new</span> CallBack<span style=color:#f92672>({...});</span>
</code></pre></div><ol start=2>
<li>设置有效的重试策略以及 acks 配置</li>
</ol>
<p>我们可以在生产者端设置一个有效的重试策略，保证消息成功发送。例如，我们可以使用指数退避算法进行重试。这种算法会在每次重试失败后等待更长的时间，从而减轻服务器的压力，并增加消息成功发送的概率。</p>
<p>通过设置 Producer acks 机制，我们可以确保生产者收到 Kafka 服务器的确认，知晓消息是否被成功提交。</p>
<ul>
<li><strong>acks=0：</strong> 生产者在发送消息后不会等待任何确认，直接将消息视为发送成功。这种设置下，可能会出现消息丢失的情况，因为生产者不会等待服务器的任何确认即认为消息发送成功。</li>
<li><strong>acks=1：</strong> 生产者在发送消息后会等待 Leader Broker 的确认，确认后即视为消息发送成功。这种设置下，消息的可靠性得到一定程度的保证，但仍有可能发生 Leader Broker 宕机导致消息丢失的情况。</li>
<li><strong>acks=all：</strong> 生产者在发送消息后会等待 Leader Broker 和所有副本的确认，确认后才视为消息发送成功。这种设置下，消息的可靠性和一致性得到最高级别的保证，但同时也会增加网络延迟和资源消耗。</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#f92672>import</span> org.apache.kafka.clients.producer.*<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> org.apache.kafka.common.serialization.StringSerializer<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> java.util.Properties<span style=color:#f92672>;</span>

<span style=color:#66d9ef>public</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>KafkaProducerExample</span> <span style=color:#f92672>{</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>final</span> String TOPIC_NAME <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;my-topic&#34;</span><span style=color:#f92672>;</span>
    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>final</span> String BOOTSTRAP_SERVERS <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;localhost:9092&#34;</span><span style=color:#f92672>;</span>

    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>main</span><span style=color:#f92672>(</span>String<span style=color:#f92672>[]</span> args<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
        Properties props <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Properties<span style=color:#f92672>();</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>BOOTSTRAP_SERVERS_CONFIG</span><span style=color:#f92672>,</span> BOOTSTRAP_SERVERS<span style=color:#f92672>);</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>KEY_SERIALIZER_CLASS_CONFIG</span><span style=color:#f92672>,</span> StringSerializer<span style=color:#f92672>.</span><span style=color:#a6e22e>class</span><span style=color:#f92672>.</span><span style=color:#a6e22e>getName</span><span style=color:#f92672>());</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>VALUE_SERIALIZER_CLASS_CONFIG</span><span style=color:#f92672>,</span> StringSerializer<span style=color:#f92672>.</span><span style=color:#a6e22e>class</span><span style=color:#f92672>.</span><span style=color:#a6e22e>getName</span><span style=color:#f92672>());</span>

        <span style=color:#75715e>// 设置重试次数为3次
</span><span style=color:#75715e></span>        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>RETRIES_CONFIG</span><span style=color:#f92672>,</span> 3<span style=color:#f92672>);</span>

		<span style=color:#75715e>// 指数退避算法参数
</span><span style=color:#75715e></span>		<span style=color:#75715e>// 初始重试间隔为1秒
</span><span style=color:#75715e></span>		props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>RETRY_BACKOFF_MS_CONFIG</span><span style=color:#f92672>,</span> 1000<span style=color:#f92672>);</span>
		<span style=color:#75715e>// 最大重试间隔为30秒
</span><span style=color:#75715e></span>		props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>RETRY_BACKOFF_MAX_MS_CONFIG</span><span style=color:#f92672>,</span> 30000<span style=color:#f92672>);</span>
		<span style=color:#75715e>// 设置 acks 配置为 all
</span><span style=color:#75715e></span>		properties<span style=color:#f92672>.</span><span style=color:#a6e22e>setProperty</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>ACKS_CONFIG</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;all&#34;</span><span style=color:#f92672>);</span>

        KafkaProducer<span style=color:#f92672>&lt;</span>String<span style=color:#f92672>,</span> String<span style=color:#f92672>&gt;</span> producer <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> KafkaProducer<span style=color:#f92672>&lt;&gt;(</span>props<span style=color:#f92672>);</span>
        <span style=color:#75715e>// ... 其他业务逻辑
</span><span style=color:#75715e></span>    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>
</code></pre></div><ol start=3>
<li>启用 Kafka 日志压缩</li>
</ol>
<p>Kafka 提供了日志压缩功能，这可以减少磁盘空间的使用，并提高消息存储的可靠性。通过这种方式，我们可以减少因磁盘满导致的消息丢失风险。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#f92672>import</span> org.apache.kafka.clients.producer.*<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> org.apache.kafka.common.serialization.StringSerializer<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> java.util.Properties<span style=color:#f92672>;</span>

<span style=color:#66d9ef>public</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>KafkaProducerExample</span> <span style=color:#f92672>{</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>final</span> String TOPIC_NAME <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;my-topic&#34;</span><span style=color:#f92672>;</span>
    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>final</span> String BOOTSTRAP_SERVERS <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;localhost:9092&#34;</span><span style=color:#f92672>;</span>

    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>main</span><span style=color:#f92672>(</span>String<span style=color:#f92672>[]</span> args<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
        Properties props <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Properties<span style=color:#f92672>();</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>BOOTSTRAP_SERVERS_CONFIG</span><span style=color:#f92672>,</span> BOOTSTRAP_SERVERS<span style=color:#f92672>);</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>KEY_SERIALIZER_CLASS_CONFIG</span><span style=color:#f92672>,</span> StringSerializer<span style=color:#f92672>.</span><span style=color:#a6e22e>class</span><span style=color:#f92672>.</span><span style=color:#a6e22e>getName</span><span style=color:#f92672>());</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>VALUE_SERIALIZER_CLASS_CONFIG</span><span style=color:#f92672>,</span> StringSerializer<span style=color:#f92672>.</span><span style=color:#a6e22e>class</span><span style=color:#f92672>.</span><span style=color:#a6e22e>getName</span><span style=color:#f92672>());</span>

        <span style=color:#75715e>// 其他设置...
</span><span style=color:#75715e></span>        <span style=color:#75715e>// 启用日志压缩，使用gzip压缩算法
</span><span style=color:#75715e></span>        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ProducerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>COMPRESSION_TYPE_CONFIG</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;gzip&#34;</span><span style=color:#f92672>);</span>
        KafkaProducer<span style=color:#f92672>&lt;</span>String<span style=color:#f92672>,</span> String<span style=color:#f92672>&gt;</span> producer <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> KafkaProducer<span style=color:#f92672>&lt;&gt;(</span>props<span style=color:#f92672>);</span>
        <span style=color:#75715e>// ... 其他业务逻辑
</span><span style=color:#75715e></span>    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>
</code></pre></div><h3 id=kafka-服务端相关方案与措施>Kafka 服务端相关方案与措施<a hidden class=anchor aria-hidden=true href=#kafka-服务端相关方案与措施>#</a></h3>
<p>在 Kafka 服务端，要保证消息的可靠性，需要从几方面考虑</p>
<p><strong>合理的配置</strong></p>
<ol>
<li>根据数据量级，配置合理的 partition 数量，提高吞吐量，避免性能瓶颈导致消息丢失</li>
</ol>
<p><strong>高可用：</strong></p>
<ol>
<li><strong>多副本配置：</strong> 在 Kafka 集群中设置多个副本，以确保即使某些 Broker 发生故障，仍然能够保证消息的可用性和一致性</li>
<li><strong>ISR（In-Sync Replicas）机制：</strong> 使用 ISR 机制来确保所有副本之间的同步性，只有在所有 ISR 中的副本都同步成功后才认为消息发送成功</li>
<li><strong>Controller 选举：</strong> 配置 Controller 选举机制，确保 Kafka 集群中的 Controller 能够及时处理 Broker 的故障和切换</li>
</ol>
<p><strong>数据持久化和日志管理：</strong></p>
<ul>
<li><strong>数据持久化策略：</strong> 配置合适的数据持久化策略，例如使用持久化日志来存储消息，保证消息不会因为服务重启或异常导致丢失。</li>
<li><strong>日志管理和清理：</strong> 定期清理过期的日志段（log segment），避免日志文件过大导致磁盘空间不足，同时确保消息的及时清理和归档。</li>
</ul>
<p><strong>监控和故障恢复：</strong></p>
<ul>
<li><strong>监控和报警：</strong> 配置监控系统，实时监测 Kafka 集群的运行状态和性能指标，并设置报警机制，在出现异常或性能下降时及时发现并处理。</li>
<li><strong>故障自愈：</strong> 配置自动故障恢复机制，例如使用 Kafka 的 Controller 自动进行 Broker 的故障检测和切换，确保集群在发生故障时能够快速恢复。</li>
</ul>
<h3 id=消费者端解决方案与措施>消费者端解决方案与措施<a hidden class=anchor aria-hidden=true href=#消费者端解决方案与措施>#</a></h3>
<p><strong>手动维护 offset</strong></p>
<ul>
<li>将 <code>enable.auto.commit</code> 设置为 <code>false</code>，并且在消费者端手动提交偏移量。</li>
<li>使用较小的 <code>auto.commit.interval.ms</code> 值，以减少自动提交偏移量的时间间隔，提高偏移量的提交频率。</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#f92672>import</span> org.apache.kafka.clients.consumer.*<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> org.apache.kafka.common.TopicPartition<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> redis.clients.jedis.Jedis<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> java.time.Duration<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> java.util.Collections<span style=color:#f92672>;</span>
<span style=color:#f92672>import</span> java.util.Properties<span style=color:#f92672>;</span>

<span style=color:#66d9ef>public</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>KafkaConsumerWithRedisOffsetOnStartup</span> <span style=color:#f92672>{</span>
    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>main</span><span style=color:#f92672>(</span>String<span style=color:#f92672>[]</span> args<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
        String kafkaBootstrapServers <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;kafka-broker1:9092,kafka-broker2:9092&#34;</span><span style=color:#f92672>;</span>
        String kafkaTopic <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;test-topic&#34;</span><span style=color:#f92672>;</span>
        String groupId <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;test-consumer-group&#34;</span><span style=color:#f92672>;</span>
        String redisHost <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;localhost&#34;</span><span style=color:#f92672>;</span>
        <span style=color:#66d9ef>int</span> redisPort <span style=color:#f92672>=</span> 6379<span style=color:#f92672>;</span>

        <span style=color:#75715e>// Kafka Consumer 配置
</span><span style=color:#75715e></span>        Properties props <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Properties<span style=color:#f92672>();</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ConsumerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>BOOTSTRAP_SERVERS_CONFIG</span><span style=color:#f92672>,</span> kafkaBootstrapServers<span style=color:#f92672>);</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ConsumerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>GROUP_ID_CONFIG</span><span style=color:#f92672>,</span> groupId<span style=color:#f92672>);</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ConsumerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>KEY_DESERIALIZER_CLASS_CONFIG</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span style=color:#f92672>);</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ConsumerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>VALUE_DESERIALIZER_CLASS_CONFIG</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span style=color:#f92672>);</span>
        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ConsumerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>ENABLE_AUTO_COMMIT_CONFIG</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;false&#34;</span><span style=color:#f92672>);</span> <span style=color:#75715e>// 关闭自动提交偏移量
</span><span style=color:#75715e></span>        props<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span>ConsumerConfig<span style=color:#f92672>.</span><span style=color:#a6e22e>AUTO_COMMIT_INTERVAL_MS_CONFIG</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;100&#34;</span><span style=color:#f92672>);</span> <span style=color:#75715e>// 设置自动提交偏移量的时间间隔为 100 毫秒
</span><span style=color:#75715e></span>
        KafkaConsumer<span style=color:#f92672>&lt;</span>String<span style=color:#f92672>,</span> String<span style=color:#f92672>&gt;</span> consumer <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> KafkaConsumer<span style=color:#f92672>&lt;&gt;(</span>props<span style=color:#f92672>);</span>

        <span style=color:#75715e>// Redis 连接
</span><span style=color:#75715e></span>        Jedis jedis <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Jedis<span style=color:#f92672>(</span>redisHost<span style=color:#f92672>,</span> redisPort<span style=color:#f92672>);</span>

        <span style=color:#66d9ef>try</span> <span style=color:#f92672>{</span>
            <span style=color:#75715e>// 从 Redis 中获取偏移量
</span><span style=color:#75715e></span>            Map<span style=color:#f92672>&lt;</span>TopicPartition<span style=color:#f92672>,</span> Long<span style=color:#f92672>&gt;</span> offsets <span style=color:#f92672>=</span> getOffsetsFromRedis<span style=color:#f92672>(</span>jedis<span style=color:#f92672>,</span> kafkaTopic<span style=color:#f92672>,</span> groupId<span style=color:#f92672>);</span>
            <span style=color:#75715e>// 订阅主题并设置偏移量
</span><span style=color:#75715e></span>            consumer<span style=color:#f92672>.</span><span style=color:#a6e22e>subscribe</span><span style=color:#f92672>(</span>Collections<span style=color:#f92672>.</span><span style=color:#a6e22e>singleton</span><span style=color:#f92672>(</span>kafkaTopic<span style=color:#f92672>),</span> <span style=color:#66d9ef>new</span> ConsumerRebalanceListener<span style=color:#f92672>()</span> <span style=color:#f92672>{</span>
                <span style=color:#a6e22e>@Override</span>
                <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>onPartitionsRevoked</span><span style=color:#f92672>(</span>Collection<span style=color:#f92672>&lt;</span>TopicPartition<span style=color:#f92672>&gt;</span> partitions<span style=color:#f92672>)</span> <span style=color:#f92672>{}</span>

                <span style=color:#a6e22e>@Override</span>
                <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>onPartitionsAssigned</span><span style=color:#f92672>(</span>Collection<span style=color:#f92672>&lt;</span>TopicPartition<span style=color:#f92672>&gt;</span> partitions<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
                    <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span>TopicPartition partition <span style=color:#f92672>:</span> partitions<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
                        consumer<span style=color:#f92672>.</span><span style=color:#a6e22e>seek</span><span style=color:#f92672>(</span>partition<span style=color:#f92672>,</span> offsets<span style=color:#f92672>.</span><span style=color:#a6e22e>getOrDefault</span><span style=color:#f92672>(</span>partition<span style=color:#f92672>,</span> 0L<span style=color:#f92672>));</span>
                    <span style=color:#f92672>}</span>
                <span style=color:#f92672>}</span>
            <span style=color:#f92672>});</span>

            <span style=color:#66d9ef>while</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>true</span><span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
                ConsumerRecords<span style=color:#f92672>&lt;</span>String<span style=color:#f92672>,</span> String<span style=color:#f92672>&gt;</span> records <span style=color:#f92672>=</span> consumer<span style=color:#f92672>.</span><span style=color:#a6e22e>poll</span><span style=color:#f92672>(</span>Duration<span style=color:#f92672>.</span><span style=color:#a6e22e>ofMillis</span><span style=color:#f92672>(</span>100<span style=color:#f92672>));</span>
                <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span>ConsumerRecord<span style=color:#f92672>&lt;</span>String<span style=color:#f92672>,</span> String<span style=color:#f92672>&gt;</span> record <span style=color:#f92672>:</span> records<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
                    System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;Received message: &#34;</span> <span style=color:#f92672>+</span> record<span style=color:#f92672>.</span><span style=color:#a6e22e>value</span><span style=color:#f92672>());</span>
                    <span style=color:#75715e>// 处理消息...
</span><span style=color:#75715e></span>                    <span style=color:#75715e>// 手动提交偏移量到 Redis
</span><span style=color:#75715e></span>                    saveOffsetInRedis<span style=color:#f92672>(</span>jedis<span style=color:#f92672>,</span> record<span style=color:#f92672>.</span><span style=color:#a6e22e>topic</span><span style=color:#f92672>(),</span> record<span style=color:#f92672>.</span><span style=color:#a6e22e>partition</span><span style=color:#f92672>(),</span> record<span style=color:#f92672>.</span><span style=color:#a6e22e>offset</span><span style=color:#f92672>());</span>
                    <span style=color:#75715e>// 手动提交偏移量到 Kafka
</span><span style=color:#75715e></span>                    consumer<span style=color:#f92672>.</span><span style=color:#a6e22e>commitSync</span><span style=color:#f92672>(</span>Collections<span style=color:#f92672>.</span><span style=color:#a6e22e>singletonMap</span><span style=color:#f92672>(</span><span style=color:#66d9ef>new</span> TopicPartition<span style=color:#f92672>(</span>record<span style=color:#f92672>.</span><span style=color:#a6e22e>topic</span><span style=color:#f92672>(),</span> record<span style=color:#f92672>.</span><span style=color:#a6e22e>partition</span><span style=color:#f92672>()),</span> <span style=color:#66d9ef>new</span> OffsetAndMetadata<span style=color:#f92672>(</span>record<span style=color:#f92672>.</span><span style=color:#a6e22e>offset</span><span style=color:#f92672>()</span> <span style=color:#f92672>+</span> 1<span style=color:#f92672>)));</span>
                <span style=color:#f92672>}</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>}</span> <span style=color:#66d9ef>finally</span> <span style=color:#f92672>{</span>
            consumer<span style=color:#f92672>.</span><span style=color:#a6e22e>close</span><span style=color:#f92672>();</span>
            jedis<span style=color:#f92672>.</span><span style=color:#a6e22e>close</span><span style=color:#f92672>();</span>
        <span style=color:#f92672>}</span>
    <span style=color:#f92672>}</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> Map<span style=color:#f92672>&lt;</span>TopicPartition<span style=color:#f92672>,</span> Long<span style=color:#f92672>&gt;</span> <span style=color:#a6e22e>getOffsetsFromRedis</span><span style=color:#f92672>(</span>Jedis jedis<span style=color:#f92672>,</span> String topic<span style=color:#f92672>,</span> String groupId<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
        Map<span style=color:#f92672>&lt;</span>TopicPartition<span style=color:#f92672>,</span> Long<span style=color:#f92672>&gt;</span> offsets <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> HashMap<span style=color:#f92672>&lt;&gt;();</span>
        <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span>String key <span style=color:#f92672>:</span> jedis<span style=color:#f92672>.</span><span style=color:#a6e22e>keys</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;offset-&#34;</span> <span style=color:#f92672>+</span> topic <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;-*&#34;</span><span style=color:#f92672>))</span> <span style=color:#f92672>{</span>
            String<span style=color:#f92672>[]</span> parts <span style=color:#f92672>=</span> key<span style=color:#f92672>.</span><span style=color:#a6e22e>split</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;-&#34;</span><span style=color:#f92672>);</span>
            <span style=color:#66d9ef>int</span> partition <span style=color:#f92672>=</span> Integer<span style=color:#f92672>.</span><span style=color:#a6e22e>parseInt</span><span style=color:#f92672>(</span>parts<span style=color:#f92672>[</span>parts<span style=color:#f92672>.</span><span style=color:#a6e22e>length</span> <span style=color:#f92672>-</span> 1<span style=color:#f92672>]);</span>
            <span style=color:#66d9ef>long</span> offset <span style=color:#f92672>=</span> Long<span style=color:#f92672>.</span><span style=color:#a6e22e>parseLong</span><span style=color:#f92672>(</span>jedis<span style=color:#f92672>.</span><span style=color:#a6e22e>get</span><span style=color:#f92672>(</span>key<span style=color:#f92672>));</span>
            offsets<span style=color:#f92672>.</span><span style=color:#a6e22e>put</span><span style=color:#f92672>(</span><span style=color:#66d9ef>new</span> TopicPartition<span style=color:#f92672>(</span>topic<span style=color:#f92672>,</span> partition<span style=color:#f92672>),</span> offset<span style=color:#f92672>);</span>
        <span style=color:#f92672>}</span>
        <span style=color:#66d9ef>return</span> offsets<span style=color:#f92672>;</span>
    <span style=color:#f92672>}</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>saveOffsetInRedis</span><span style=color:#f92672>(</span>Jedis jedis<span style=color:#f92672>,</span> String topic<span style=color:#f92672>,</span> <span style=color:#66d9ef>int</span> partition<span style=color:#f92672>,</span> <span style=color:#66d9ef>long</span> offset<span style=color:#f92672>)</span> <span style=color:#f92672>{</span>
        String key <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;offset-&#34;</span> <span style=color:#f92672>+</span> topic <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;-&#34;</span> <span style=color:#f92672>+</span> partition<span style=color:#f92672>;</span>
        jedis<span style=color:#f92672>.</span><span style=color:#a6e22e>set</span><span style=color:#f92672>(</span>key<span style=color:#f92672>,</span> String<span style=color:#f92672>.</span><span style=color:#a6e22e>valueOf</span><span style=color:#f92672>(</span>offset<span style=color:#f92672>));</span>
    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>
</code></pre></div><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2>
<p>总得来说，关于消息可靠性的保证，需要从生产端、服务端、消费端三个方面综合考虑，不是仅仅一个方面的问题。</p>
<h2 id=拓展>拓展<a hidden class=anchor aria-hidden=true href=#拓展>#</a></h2>
<p><strong>Kafka 官方常用工具</strong></p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># 查看某个topic的message数量</span>
$ ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test_topic
<span style=color:#75715e># 查看consumer Group列表</span>
$ ./kafka-consumer-groups.sh  --list  --bootstrap-server 192.168.88.108:9092
<span style=color:#75715e># 查看 offset 消费情况</span>
$ ./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group console-consumer-1152 --describe
GROUP                 TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                           HOST            CLIENT-ID
console-consumer-1152 test_topic      0          -               4               -               consumer-console-consumer-1152-1-2703ea2b-b62d-4cfd-8950-34e8c321b942 /127.0.0.1      consumer-console-consumer-1152-1
</code></pre></div><p><strong>Kafka  日志刷盘机制</strong></p>
<pre tabindex=0><code># 推荐采用默认值，即不配置该配置，交由操作系统自行决定何时落盘，以提升性能。
# 针对 broker 配置：
log.flush.interval.messages=10000 # 日志落盘消息条数间隔，即每接收到一定条数消息，即进行log落盘。
log.flush.interval.ms=1000        # 日志落盘时间间隔，单位ms，即每隔一定时间，即进行log落盘。

# 针对 topic 配置：
flush.messages.flush.ms=1000  # topic下每1s刷盘
flush.messages=1              # topic下每个消息都落盘

# 查看 Linux 后台线程执行配置
$ sysctl -a | grep dirty
vm.dirty_background_bytes = 0
vm.dirty_background_ratio = 10      # 表示当脏页占总内存的的百分比超过这个值时，后台线程开始刷新脏页。
vm.dirty_bytes = 0
vm.dirty_expire_centisecs = 3000    # 表示脏数据多久会被刷新到磁盘上（30秒）。
vm.dirty_ratio = 20
vm.dirty_writeback_centisecs = 500  # 表示多久唤醒一次刷新脏页的后台线程（５秒）。
vm.dirtytime_expire_seconds = 43200
</code></pre>
</div>
<link href=https://comment.fascloud.org/dist/Artalk.css rel=stylesheet>
<style>.dark .atk-main-editor{background-color:#37383e!important;border:1px solid #555660!important}.dark .artalk{color:#bdbdbe!important}.dark .atk-main-editor>.atk-textarea-wrap>.atk-textarea{background-color:#37383e!important;color:#bdbdbe!important}.dark .atk-editor-plug-emoticons>.atk-grp-switcher{background:#37383e!important;border-top:1px solid #555660!important;border-bottom:1px solid #555660!important}.dark .atk-editor-plug-emoticons>.atk-grp-switcher>span:hover,.dark .atk-editor-plug-emoticons>.atk-grp-switcher>span.active{background:#262629!important}.dark .atk-main-editor>.atk-plug-panel-wrap{border-top:1px solid #555660!important}.dark .atk-comment>.atk-main>.atk-header .badge,.atk-comment>.atk-main>.atk-header .atk-ua,.atk-comment>.atk-main>.atk-header .atk-pinned-badge,.atk-comment>.atk-main>.atk-header .atk-region-badge,.atk-comment>.atk-main>.atk-header .atk-badge{color:#bdc6d9!important;background:#000!important}.dark .atk-main-editor>.atk-textarea-wrap>.atk-send-reply{background:rgb(134 134 134/75%)!important}.comment-split-line{text-align:center;font-size:14px;border-bottom:1px solid #eaecef;margin:50px 0;height:0}.comment-split-line::after{content:"评论";background-color:#ececec;border-radius:10px;padding:0 10px;position:relative;top:-10px;color:#6a737d}.dark .comment-split-line::after{background-color:#37383e;color:#bdc6d9}.dark .comment-split-line{border-bottom:1px solid #555660}</style>
<script src=https://comment.fascloud.org/dist/Artalk.js></script>
<div class=comment-split-line></div>
<div id=Comments></div>
<script>Artalk.init({el:'#Comments',pageKey:'',pageTitle:'',server:'https://comment.fascloud.org/',site:'blog-hushuo'})</script>
</article>
</main>
<footer class=footer>
<span>&copy; 2024 <a href=https://blog.zhangyingwei.com/>胡说</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
<span>
订阅
<a href=/index.xml rel=noopener target=_blank>RSS</a>
</span>
</footer>
<a href=# aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script></script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode;b.classList.add('font-activate');const a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script></body>
</html>